{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training dataset\n",
    "dataset = torchvision.datasets.MNIST(root='./data',train = True, download=True,transform = torchvision.transforms.ToTensor())\n",
    "\n",
    "# data gets loaded in the train_dataset variable\n",
    "# root parameter specifies the loacation where the data exists/has to be downloaded to\n",
    "# download parameter being set as 'True' instructs to download the MNIST dataset if not present in the root specified location\n",
    "# transfrom parameter transforms the dataset to the specified datatype, here it is torch.FloatTensor and the values are scaled down to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset))           # printing datatype of 'training_dataset'\n",
    "print(dataset)                 # printing 'training_dataset'\n",
    "print(type(dataset[0]))        # printing datatype of what is stored at index 0 in the 'training_dataset'\n",
    "print(dataset[0])              # printing what is present at index 0 in the 'training_dataset'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c10a1364",
   "metadata": {},
   "source": [
    "* 'train_dataset' contains 60000 tuples, each tuple consists of one tensor containing 'info' about the \n",
    "  (28 x 28 = 784)pixels and an integer.\n",
    "* This 'info' is usually a PIL Image, but while loading the data I used transform parameter to transform PIL Image   to tensor. \n",
    "  NOTE : torchvision.tranforms.ToTensor() by default scales the values within the tensors to [0,1]\n",
    "* That's why I am getting these 1x28x28 tensors each entry corresponding to the intensity(darkness as values are     higher) of pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fb7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 10 tensors along with there corresponding labels\n",
    "for i in range(10) :\n",
    "    print(f\"tensors for image {i+1} with label {dataset[i][1]} : \\n{dataset[i][0]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 10 labels seperately :\n",
    "for i in range(10) :\n",
    "    print(f\"label for image {i+1} : {dataset[i][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dba4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using matplotlib to print the first 10 image \n",
    "for i in range(10) :\n",
    "\n",
    "    pixel_values = dataset[i][0][0]       # selecting the tensor that stores the pixel-information of the 'i'th image\n",
    "\n",
    "# displaying the grayscale image using matplotlib.pyplot\n",
    "    plt.imshow(pixel_values, cmap='gray_r', vmin=0, vmax=1)\n",
    "    plt.title(dataset[i][1])\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "# values on top of the image correspond to the label for that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening the images :\n",
    "\n",
    "# defining flatten function which takes in a 1 x 28 x 28 tensor and returns a tranformed 2D tensor with shape (1,784)  \n",
    "def flatten(x) :\n",
    "    a = torch.empty(0)\n",
    "    for i in range(28) :\n",
    "        a = torch.cat((a,x[0,i]))\n",
    "    return a\n",
    "\n",
    "# defining X_train, which is the matrix which will contain all 60k datapoints, which we will be using to training our model\n",
    "X_train = torch.empty(60000,784)\n",
    "\n",
    "for i in range(60000):\n",
    "    X_train[i] = flatten(dataset[i][0])\n",
    "\n",
    "print(X_train.shape)        # it is supposed to have a shape (60000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f74fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing first 5 datapoints/rows from X_train :\n",
    "for i in range(5) :\n",
    "    print(f\"Row {i+1} : {X_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining y_train which will store the correct labels corresponding to data-tensors in X_train\n",
    "y_train = torch.empty(60000,1,dtype = torch.int32)\n",
    "for i in range(60000):\n",
    "    y_train[i] = dataset[i][1]\n",
    "   \n",
    "print(y_train.shape)   # it is supposed to have a shape (60000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization : it is done for all features independently\n",
    "# We'll be simply dividing each entry of all the feature columns(784) by the respective maximum value which that feature takes\n",
    "# uncomment code below to run Normalization :\n",
    "'''\n",
    " for i in range(784) :\n",
    "     X_train[:,i] /= X_train[:,i].max().item()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb09282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values in X_train and Y_train :\n",
    "# if any exists, then I'll be removing that datapoint from both X_train and y_train\n",
    "# NOTE : this may take a minute as all the values in X_train and y_train are being checked\n",
    "for i in range(len(y_train)) : \n",
    "    if (y_train[i].item() == None) :                                \n",
    "        y_train = torch.cat((y_train[0:i],y_train[i+1,len(y_train)]), axis = 0)\n",
    "        X_train = torch.cat((X_train[0:i],X_train[i+1,len(X_train)]), axis = 0)\n",
    "        continue\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        if (X_train[i,j].item() == None) : \n",
    "            y_train = torch.cat((y_train[0:i],y_train[i+1,len(y_train)]), axis = 0)\n",
    "            X_train = torch.cat((X_train[0:i],X_train[i+1,len(X_train)]), axis = 0)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d09605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)    \n",
    "# if X_train.shape : [60000,784] and y_train.shape : [60000,1] => no missing values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of labels :\n",
    "Total_count = 0\n",
    "for i in range(10) :\n",
    "    count = torch.eq(y_train, i).sum().item()     \n",
    "    Total_count += count;\n",
    "    print(f\"No. of data points with true label {i} are {count}\")\n",
    "print(f\"Total count : {Total_count}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbe702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some examples from each class :\n",
    "# total 50 examples shown in increasing order...\n",
    "for i in range(10) :\n",
    "    print(f\"Some samples with label {i} are : \")\n",
    "    for j in range(50) :\n",
    "        if (i==dataset[j][1]):\n",
    "            pixel_values = dataset[j][0][0]\n",
    "            plt.imshow(pixel_values, cmap='gray_r', vmin=0, vmax=1)\n",
    "            plt.axis('on')\n",
    "            plt.show()\n",
    "    print(\"------------------------------\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42842c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing 10 samples randomly along with there labels\n",
    "for i in range(10) :\n",
    "    random_number = random.randrange(-1, 60000) \n",
    "    pixel_values = dataset[random_number][0][0]\n",
    "    plt.imshow(pixel_values, cmap='gray_r', vmin=0, vmax=1)\n",
    "    plt.axis('on')\n",
    "    print(f\"Label for sample below is : {y_train[random_number].item()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee82c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAR CHART : showing the distribution of different digits in the dataset\n",
    "a = np.zeros(10,dtype = np.int32)\n",
    "for i in range(10) :\n",
    "    count = torch.eq(y_train, i).sum().item()\n",
    "    a[i] = count\n",
    "print(a)\n",
    "\n",
    "plt.bar([0,1,2,3,4,5,6,7,8,9], a, align='center', alpha=1)\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will rotate x number of randomly selected images from dataset by any random angle between -theta and theta \n",
    "# it returns a tensor with shape (x,784)\n",
    "def rotate(dataset,x,theta = 30) :\n",
    "    a = torch.empty(x,784)\n",
    "    b = torch.empty(x,1)\n",
    "    rotation_transform = torchvision.transforms.RandomAffine(degrees=(-theta,theta),scale=(1,1))\n",
    "    for i in range(x) :\n",
    "        rnum = random.randrange(-1, 60000)\n",
    "        rotated_image = rotation_transform(dataset[rnum][0])\n",
    "        a[i] = flatten(rotated_image)          # function is defined in some cell above\n",
    "        b[i] = dataset[rnum][1]\n",
    "        # printing some samples of rotated images\n",
    "        if (i%600==0) :\n",
    "            print(f\"Label corresponding to this image is {int(b[i].item())}\")\n",
    "            print(\"This is a rotated version\")\n",
    "            show_image(rotated_image)\n",
    "            print(\"----------------------------------------------\\n\")\n",
    "    return a,b\n",
    "\n",
    "\n",
    "# this function will scale x number of randomly selected images from dataset by any factor rangeing from scale_min to scale max\n",
    "# it returns a tensor with shape (x,784)\n",
    "def scale(dataset,x,scale_min = 0.8,scale_max = 1.2) :\n",
    "    a = torch.empty(x,784)\n",
    "    b = torch.empty(x,1)\n",
    "    scaling_transform = torchvision.transforms.RandomAffine(degrees=0, scale=(scale_min, scale_max))\n",
    "    for i in range(x) :\n",
    "        rnum = random.randrange(-1, 60000)\n",
    "        scaled_image = scaling_transform(dataset[rnum][0])\n",
    "        a[i] = flatten(scaled_image)          # function is defined in some cell above\n",
    "        b[i] = dataset[rnum][1]\n",
    "        # printing some samples of scaled images\n",
    "        if (i%600==0) :\n",
    "            print(f\"Label corresponding to this image is {int(b[i].item())}\")\n",
    "            print(\"This is a scaled version\")\n",
    "            show_image(scaled_image)\n",
    "            print(\"----------------------------------------------\\n\")\n",
    "    return a,b \n",
    "\n",
    "\n",
    "# this is a combination of above two functions\n",
    "# it returns a tensor with shape (x,784)\n",
    "def rotate_scale(dataset,x,theta = 30,scale_min = 0.8,scale_max = 1.2) :\n",
    "    a = torch.empty(x,784)\n",
    "    b = torch.empty(x,1)\n",
    "    transform_ = torchvision.transforms.RandomAffine(degrees=(-theta,theta), scale=(scale_min, scale_max))\n",
    "    for i in range(x) :\n",
    "        rnum = random.randrange(-1, 60000)\n",
    "        image = transform_(dataset[rnum][0])\n",
    "        a[i] = flatten(image)          # function is defined in some cell above\n",
    "        b[i] = dataset[rnum][1]\n",
    "        # printing some samples of rotated-scaled images\n",
    "        if (i%600==0) :\n",
    "            print(f\"Label corresponding to this image is {int(b[i].item())}\")\n",
    "            print(\"This is a rotated-scaled version\")\n",
    "            show_image(image)\n",
    "            print(\"----------------------------------------------\\n\")\n",
    "    return a,b \n",
    "\n",
    "# this functions prints the image corresponding to the given 1 x 28 x 28 tensor\n",
    "def show_image(tensor):\n",
    "    plt.imshow(tensor.numpy()[0], cmap='gray_r')\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I'll be rotating 3000, scaling 3000 and rotating-scaling 4000 randomly selected images from the current dataset\n",
    "# these will be concatenated to the original training set X_train\n",
    "\n",
    "a,b = rotate(dataset,3000,25)\n",
    "X_train = torch.cat((X_train,a), axis = 0)\n",
    "y_train = torch.cat((y_train,b), axis = 0)\n",
    "\n",
    "c,d = scale(dataset,3000,0.8,1.2)\n",
    "X_train = torch.cat((X_train,c), axis = 0)\n",
    "y_train = torch.cat((y_train,d), axis = 0)\n",
    "\n",
    "e,f = rotate_scale(dataset,4000,25,0.8,1.2)\n",
    "X_train = torch.cat((X_train,e), axis = 0)\n",
    "y_train = torch.cat((y_train,f), axis = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f76165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were too many zeros in the dataset... hence the cross entropy loss went to infinity due to operations on these zero valued dataset...\n",
    "# to avoid this, I subtracted 1 from all the values in the training and testing set... This won't cause any change in the procedure or so... \n",
    "# used broadcasting\n",
    "X_train = 1 - X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Normalization :\n",
    "# (x - mu)/std , where mu(mean) and std(standard deviation) are of respective feature columns\n",
    "# storing mu and std for each feature column for Normalizing the test_dataset with the same parameters\n",
    "\n",
    "'''\n",
    "mu = torch.empty(784)\n",
    "std = torch.empty(784)\n",
    "for i in range(784) :\n",
    "    mu[i] = X_train[:,i].mean().item();\n",
    "    std[i] = X_train[:,i].std().item();\n",
    "    X_train[:,i] = (X_train[:,i]-mu[i])/std[i]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# splitting the data into train and test set :\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, random_state = 41) \n",
    "# the dataset made above X_train will be split into 2 parts, 85 % of it will be used to train the model and rest for testing\n",
    "\n",
    "y_train = y_train.long()   # necessary step, else will give error while using criterion (error calc. step)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550e193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bee919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "35af52ce",
   "metadata": {},
   "source": [
    "---------------- WEEK 1 HW ENDS--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614651b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63cb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downlading the test dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data',train = False, download=True,transform = torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802def23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating small batches of images , batch size = 10\n",
    "train_loader = torch.utils.data.DataLoader(dataset,batch_size = 10,shuffle = True) \n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size = 10,shuffle = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a \"CNN\" class for defining the behaviour of my neural network\n",
    "class CNN(torch.nn.Module) :\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolution Layers :\n",
    "        self.conv1 = torch.nn.Conv2d(1 , 16 , 5 , 1)    # first convolution layer has a kernel size of 5, strides by 1 unit, input features = 1 and outputs 16 feature maps\n",
    "        self.conv2 = torch.nn.Conv2d(16 , 32 , 3 , 1)   # first convolution layer has a kernel size of 3, strides by 1 unit, input features = 16 and outputs 32 feature maps\n",
    "         \n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)             # BATCH NORMALIZATION\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(120)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(70)\n",
    "        \n",
    "        # Fully connected layers : \n",
    "        self.fc1 = torch.nn.Linear(5*5*32 , 120)        # no. of inputs to each neuron in this layer will bw 5*5*32 because we will be left with 32 feature maps after 2nd pooling and each will have a size of 5*5\n",
    "                                                        # setting number of neurons to be 120 in this layer\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(120 , 70)            # setting number of neurons to be 70 in this layer\n",
    "        self.fc3 = torch.nn.Linear(70 , 10)             # setting number of neurons to be 10 in this layer\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        # 1st pass\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(self.bn1(x))     # using RelU as activation function\n",
    "        x = torch.nn.functional.max_pool2d(x,2,2)     # pooling down the feature map with a filter with kernal = 2 and stride = 2\n",
    "        # 2nd pass\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(self.bn2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x,2,2)\n",
    "    \n",
    "        # processing for fully connected layers, flattening out the 2D tensor \n",
    "        \n",
    "        x = x.view(-1,5*5*32)\n",
    "        \n",
    "        # passing through fully connected layers \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(self.bn3(x))       # using RelU as activation function\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.functional.relu(self.bn4(x))\n",
    "        x = self.fc3(x) \n",
    "        x = torch.nn.functional.log_softmax(x , dim = 1)  # using log_softmax as the last activation function to normalize the output of a network to a probability distribution over the output class\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e208255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Model\n",
    "torch.manual_seed(10425)\n",
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting criterion of the model to measure error. We have chosen to measure the Cross Entropy Error.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Using Adam Optimizer to optimize the parameters of the CNN\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # setting learning rate to be 0.0001 , can be changed in future\n",
    "# Here, model.parameters() are the parameter which that Model class consists of...\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our Model :\n",
    "num_iterations = 500   # the num of times we will be sending our data across the model/NN\n",
    "for i in range(num_iterations) :\n",
    "    netloss = 0 \n",
    "\n",
    "    # forward propagation :\n",
    "    \n",
    "    for b, (X_train,y_train) in enumerate(train_loader) :\n",
    "        b+=1\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred,y_train)\n",
    "        netloss += loss\n",
    "        if (b%1000 == 0) :\n",
    "            print(f\"iteration number : {i+1}  , batch number : {b},  loss : {netloss}\")  \n",
    "    print(f\"Net loss after iteration number {i+1} : {netloss}\")\n",
    "    \n",
    "    # back propagation and updation of weights and biases :\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98813168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "Y_test = torch.empty(0)\n",
    "Predicted = torch.empty(0)\n",
    "with torch.no_grad():      # No grad because we don't want any gradient as we don't want to update the weights and biases\n",
    "    correct = 0\n",
    "    for i,(X_test,y_test) in enumerate(test_loader) :\n",
    "        y_val = model.forward(X_test)\n",
    "        predicted = torch.max(y_val.data, 1)[1]\n",
    "        \n",
    "        Y_test = torch.cat((Y_test,y_test),0)\n",
    "        Predicted = torch.cat((Predicted,predicted),0)\n",
    "        \n",
    "        correct += (predicted == y_test).sum() \n",
    "    print(f\"Accuracy = {correct/100}%\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85005546",
   "metadata": {},
   "source": [
    "Achieved an accuracy of 96.85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the confusion matrix using Scikit-Learn functions\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test,Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed476f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = unique_labels(Y_test)\n",
    "column = [f\"{label}\" for label in labels]\n",
    "row = [f\"{label}\" for label in labels]\n",
    "table = pd.DataFrame(confusion_matrix(Y_test,Predicted),columns= column, index = row)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8055a46",
   "metadata": {},
   "source": [
    "In the above Confusion matrix: \n",
    "    Rows wise we have number of times that digit truely occured and,\n",
    "    Column wise we have number of times that digit was predicted.\n",
    "    \n",
    "On analyzing the above Confusion matrix, we can conclude that:\n",
    "1) the model had quite often (40 times) recognised digit 7 as digit 2.\n",
    "2) the model had quite often (35 times) recognised digit 9 as digit 4.\n",
    "3) the model had most precisely predicted the digit 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
