{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                      # importing core library for pytorch \n",
    "import torchvision                # importing pytorch library used for CV tasks\n",
    "import numpy as np                # used for addressing array/matrix operations\n",
    "import matplotlib.pyplot as plt   # used for visualizing data\n",
    "from torchvision import datasets  # from 'torchvision' package(used for CV tasks) importing module 'datasets' which has various standard datasets used for CV tasks \n",
    "import random\n",
    "\n",
    "# Loading the training dataset \n",
    "train_dataset = datasets.MNIST(root='./data',train = True, download=True,transform = torchvision.transforms.ToTensor())\n",
    "# data gets loaded in the train_dataset variable\n",
    "# root parameter specifies the loacation where the data exists/has to be downloaded to\n",
    "# download parameter being set as 'True' instructs to download the MNIST dataset if not present in the root specified location\n",
    "# transfrom parameter transforms the dataset to the specified datatype, here it is torch.FloatTensor and the values are scaled down to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbe7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_dataset))           # printing datatype of 'training_dataset'\n",
    "print(train_dataset)                 # printing 'training_dataset'\n",
    "print(type(train_dataset[0]))        # printing datatype of what is stored at index 0 in the 'training_dataset'\n",
    "print(train_dataset[0])              # printing what is present at index 0 in the 'training_dataset'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "080ed457",
   "metadata": {},
   "source": [
    "* 'train_dataset' contains 60000 tuples, each tuple consists of one tensor containing 'info' about the \n",
    "  (28 x 28 = 784)pixels and an integer.\n",
    "* This 'info' is usually a PIL Image, but while loading the data I used transform parameter to transform PIL Image   to tensor. \n",
    "  NOTE : torchvision.tranforms.ToTensor() by default scales the values within the tensors to [0,1]\n",
    "* That's why I am getting these 1x28x28 tensors each entry corresponding to the intensity(darkness as values are     higher) of pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 10 tensors along with there corresponding labels\n",
    "for i in range(10) :\n",
    "    print(f\"tensors for image {i+1} with label {train_dataset[i][1]} : \\n{train_dataset[i][0]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 10 labels seperately :\n",
    "for i in range(10) :\n",
    "    print(f\"label for image {i+1} : {train_dataset[i][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using matplotlib to print the first 10 image \n",
    "for i in range(10) :\n",
    "\n",
    "    pixel_values = train_dataset[i][0][0]       # selecting the tensor that stores the pixel-information of the 'i'th image\n",
    "\n",
    "# displaying the grayscale image using matplotlib.pyplot\n",
    "    plt.imshow(pixel_values, cmap='gray_r', vmin=0, vmax=1)\n",
    "    plt.title(train_dataset[i][1])\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "# values on top of the image correspond to the label for that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening the images :\n",
    "\n",
    "# defining flatten function which takes in a 1 x 28 x 28 tensor and returns a tranformed 2D tensor with shape (1,784)  \n",
    "def flatten(x) :\n",
    "    a = torch.empty(0)\n",
    "    for i in range(28) :\n",
    "        a = torch.cat((a,x[0,i]))\n",
    "    return a\n",
    "\n",
    "# defining X_train, which is the matrix which will contain all 60k datapoints, which we will be using to training our model\n",
    "X_train = torch.empty(60000,784)\n",
    "\n",
    "for i in range(60000):\n",
    "    X_train[i] = flatten(train_dataset[i][0])\n",
    "\n",
    "print(X_train.shape)        # it is supposed to have a shape (60000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d307320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing first 5 datapoints/rows from X_train :\n",
    "for i in range(5) :\n",
    "    print(f\"Row {i+1} : {X_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb166b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining y_train which will store the correct labels corresponding to data-tensors in X_train\n",
    "y_train = torch.empty(60000,1,dtype = torch.int32)\n",
    "for i in range(60000):\n",
    "    y_train[i] = train_dataset[i][1]\n",
    "   \n",
    "print(y_train.shape)   # it is supposed to have a shape (60000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization : it is done for all features independently\n",
    "# We'll be simply dividing each entry of all the feature columns(784) by the respective maximum value which that feature takes\n",
    "# uncomment code below to run Normalization :\n",
    "'''\n",
    " for i in range(784) :\n",
    "     X_train[:,i] /= X_train[:,i].max().item()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58347e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values in X_train and Y_train :\n",
    "# if any exists, then I'll be removing that datapoint from both X_train and y_train\n",
    "# NOTE : this may take a minute as all the values in X_train and y_train are being checked\n",
    "for i in range(len(y_train)) : \n",
    "    if (y_train[i].item() == None) :                                \n",
    "        y_train = torch.cat((y_train[0:i],y_train[i+1,len(y_train)]), axis = 0)\n",
    "        X_train = torch.cat((X_train[0:i],X_train[i+1,len(X_train)]), axis = 0)\n",
    "        continue\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        if (X_train[i,j].item() == None) : \n",
    "            y_train = torch.cat((y_train[0:i],y_train[i+1,len(y_train)]), axis = 0)\n",
    "            X_train = torch.cat((X_train[0:i],X_train[i+1,len(X_train)]), axis = 0)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3058f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)    \n",
    "# if X_train.shape : [60000,784] and y_train.shape : [60000,1] => no missing values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of labels :\n",
    "Total_count = 0\n",
    "for i in range(10) :\n",
    "    count = torch.eq(y_train, i).sum().item()     \n",
    "    Total_count += count;\n",
    "    print(f\"No. of data points with true label {i} are {count}\")\n",
    "print(f\"Total count : {Total_count}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd1ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some examples from each class :\n",
    "# total 50 examples shown in increasing order...\n",
    "for i in range(10) :\n",
    "    print(f\"Some samples with label {i} are : \")\n",
    "    for j in range(50) :\n",
    "        if (i==train_dataset[j][1]):\n",
    "            pixel_values = train_dataset[j][0][0]\n",
    "            plt.imshow(pixel_values, cmap='gray_r', vmin=0, vmax=1)\n",
    "            plt.axis('on')\n",
    "            plt.show()\n",
    "    print(\"------------------------------\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f141e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing 10 samples randomly along with there labels\n",
    "for i in range(10) :\n",
    "    random_number = random.randrange(-1, 60000) \n",
    "    pixel_values = train_dataset[random_number][0][0]\n",
    "    plt.imshow(pixel_values, cmap='gray_r', vmin=0, vmax=1)\n",
    "    plt.axis('on')\n",
    "    print(f\"Label for sample below is : {y_train[random_number].item()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAR CHART : showing the distribution of different digits in the dataset\n",
    "a = np.zeros(10,dtype = np.int32)\n",
    "for i in range(10) :\n",
    "    count = torch.eq(y_train, i).sum().item()\n",
    "    a[i] = count\n",
    "print(a)\n",
    "\n",
    "plt.bar([0,1,2,3,4,5,6,7,8,9], a, align='center', alpha=1)\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093122f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will rotate x number of randomly selected images from dataset by any random angle between -theta and theta \n",
    "# it returns a tensor with shape (x,784)\n",
    "def rotate(dataset,x,theta = 30) :\n",
    "    a = torch.empty(x,784)\n",
    "    b = torch.empty(x,1)\n",
    "    rotation_transform = torchvision.transforms.RandomAffine(degrees=(-theta,theta),scale=(1,1))\n",
    "    for i in range(x) :\n",
    "        rnum = random.randrange(-1, 60000)\n",
    "        rotated_image = rotation_transform(dataset[rnum][0])\n",
    "        a[i] = flatten(rotated_image)          # function is defined in some cell above\n",
    "        b[i] = dataset[rnum][1]\n",
    "        # printing some samples of rotated images\n",
    "        if (i%600==0) :\n",
    "            print(f\"Label corresponding to this image is {int(b[i].item())}\")\n",
    "            print(\"This is a rotated version\")\n",
    "            show_image(rotated_image)\n",
    "            print(\"----------------------------------------------\\n\")\n",
    "    return a,b\n",
    "\n",
    "\n",
    "# this function will scale x number of randomly selected images from dataset by any factor rangeing from scale_min to scale max\n",
    "# it returns a tensor with shape (x,784)\n",
    "def scale(dataset,x,scale_min = 0.8,scale_max = 1.2) :\n",
    "    a = torch.empty(x,784)\n",
    "    b = torch.empty(x,1)\n",
    "    scaling_transform = torchvision.transforms.RandomAffine(degrees=0, scale=(scale_min, scale_max))\n",
    "    for i in range(x) :\n",
    "        rnum = random.randrange(-1, 60000)\n",
    "        scaled_image = scaling_transform(dataset[rnum][0])\n",
    "        a[i] = flatten(scaled_image)          # function is defined in some cell above\n",
    "        b[i] = dataset[rnum][1]\n",
    "        # printing some samples of scaled images\n",
    "        if (i%600==0) :\n",
    "            print(f\"Label corresponding to this image is {int(b[i].item())}\")\n",
    "            print(\"This is a scaled version\")\n",
    "            show_image(scaled_image)\n",
    "            print(\"----------------------------------------------\\n\")\n",
    "    return a,b \n",
    "\n",
    "\n",
    "# this is a combination of above two functions\n",
    "# it returns a tensor with shape (x,784)\n",
    "def rotate_scale(dataset,x,theta = 30,scale_min = 0.8,scale_max = 1.2) :\n",
    "    a = torch.empty(x,784)\n",
    "    b = torch.empty(x,1)\n",
    "    transform_ = torchvision.transforms.RandomAffine(degrees=(-theta,theta), scale=(scale_min, scale_max))\n",
    "    for i in range(x) :\n",
    "        rnum = random.randrange(-1, 60000)\n",
    "        image = transform_(dataset[rnum][0])\n",
    "        a[i] = flatten(image)          # function is defined in some cell above\n",
    "        b[i] = dataset[rnum][1]\n",
    "        # printing some samples of rotated-scaled images\n",
    "        if (i%600==0) :\n",
    "            print(f\"Label corresponding to this image is {int(b[i].item())}\")\n",
    "            print(\"This is a rotated-scaled version\")\n",
    "            show_image(image)\n",
    "            print(\"----------------------------------------------\\n\")\n",
    "    return a,b \n",
    "\n",
    "# this functions prints the image corresponding to the given 1 x 28 x 28 tensor\n",
    "def show_image(tensor):\n",
    "    plt.imshow(tensor.numpy()[0], cmap='gray_r')\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d278e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I'll be rotating 3000, scaling 3000 and rotating-scaling 4000 randomly selected images from the current dataset\n",
    "# these will be concatenated to the original training set X_train\n",
    "\n",
    "a,b = rotate(train_dataset,3000,25)\n",
    "X_train = torch.cat((X_train,a), axis = 0)\n",
    "y_train = torch.cat((y_train,b), axis = 0)\n",
    "\n",
    "c,d = scale(train_dataset,3000,0.8,1.2)\n",
    "X_train = torch.cat((X_train,c), axis = 0)\n",
    "y_train = torch.cat((y_train,d), axis = 0)\n",
    "\n",
    "e,f = rotate_scale(train_dataset,4000,25,0.8,1.2)\n",
    "X_train = torch.cat((X_train,e), axis = 0)\n",
    "y_train = torch.cat((y_train,f), axis = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were too many zeros in the dataset... hence the cross entropy loss went to infinity due to operations on these zero valued dataset...\n",
    "# to avoid this, I subtracted 1 from all the values in the training and testing set... This won't cause any change in the procedure or so... \n",
    "for i in range(X_train.shape[0]) :\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        X_train[i][j] = 1 - X_train[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c62343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Normalization :\n",
    "# (x - mu)/std , where mu(mean) and std(standard deviation) are of respective feature columns\n",
    "# storing mu and std for each feature column for Normalizing the test_dataset with the same parameters\n",
    "\n",
    "'''\n",
    "mu = torch.empty(784)\n",
    "std = torch.empty(784)\n",
    "for i in range(784) :\n",
    "    mu[i] = X_train[:,i].mean().item();\n",
    "    std[i] = X_train[:,i].std().item();\n",
    "    X_train[:,i] = (X_train[:,i]-mu[i])/std[i]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b1a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Model class that inherits nn.Module\n",
    "class Model(nn.Module) :\n",
    "    # input layer(784 features)  --->   Hidden Layer 1 (25 neurons)   --->  Hidden Layer 2 (15 neurons)   --->   output layer(1 neuron)\n",
    "    def __init__(self , in_features = 784 , h1 = 25 , h2 = 15 , out_features = 10) :\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.out = nn.Linear(h2,out_features)\n",
    "        \n",
    "    # creating function for forward propagation :\n",
    "    def forward_prop(self,x) : \n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.relu(self.out(x))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3966) \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test set :\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, random_state = 41) \n",
    "# the dataset made above X_train will be split into 2 parts, 85 % of it will be used to train the model and rest for testing\n",
    "\n",
    "y_train = y_train.long()   # necessary step, else will give error while using criterion (error calc. step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74018149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting criterion of the model to measure error. We have chosen to measure the Cross Entropy Error.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Using Adam Optimizer to optimize the parameters of the NN\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003) # setting learning rate to be 0.01 , can be changed in future\n",
    "# Here, model.parameters() are the parameter which that Model class consists of...\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model :\n",
    "num_iterations = 100000   # the num of times we will be sending our data across the model/NN\n",
    "for i in range(num_iterations) :\n",
    "    \n",
    "    # forward propagation :\n",
    "    \n",
    "    y_pred = model.forward_prop(X_train)\n",
    "    loss = criterion(y_pred,y_train.squeeze(1))\n",
    "    \n",
    "    if i%100 == 0 :\n",
    "        print(f\"iteration number : {i} , loss : {loss}\")\n",
    "    \n",
    "    # back propagation and updation of weights and biases :\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e10257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for accuracy of trained model\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test) :\n",
    "        y_val = model.forward_prop(data)\n",
    "        print(f'{i+1}.) {y_test[i].item()} \\t {y_val.argmax().item()}')\n",
    "        if y_test[i].item() == y_val.argmax().item() :\n",
    "            correct = correct + 1 \n",
    "    print(correct*100/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca27307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# achieved an accuracy of 89.4 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
